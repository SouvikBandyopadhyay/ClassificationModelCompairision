{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SouvikBandyopadhyay/ClassificationModelCompairision/blob/main/MathsAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XbXSUdu5s96"
      },
      "source": [
        "### Name: Souvik Bandyopadhyay\n",
        "### Enrollment No.: 2023CSM011\n",
        "### Subject: Maths for CS\n",
        "### M.Tech 1st Sem, Session 2023-24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03A-6z3f5s9-"
      },
      "source": [
        "# Question\n",
        "## Assignment 1: 20 marks\n",
        "\n",
        "Consider any dataset from any online machine learning data repository. Split the data in 80-20 ratio for train and test dataset (can also perform k-fold cross validation if dataset is big enough). Perform feature selection using Core and Reduct (Rough Set Theory). Then perform:\n",
        "* i. Rule based Classification (using Decision Matrix from Rough Set Theory)\n",
        "* ii. Decision Tree Classifier\n",
        "* iii. Naive Bayes Classifier\n",
        "\n",
        "## Output:\n",
        "* i. Print Accuracy, Precision, Recall, F1 Score against training dataset.\n",
        "* ii. Print Accuracy, Precision, Recall, F1 Score against test dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2feQmEe5s9_"
      },
      "source": [
        "# Answer\n",
        "# Introduction\n",
        "\n",
        "* This project aims to compare the performance of 3 classifier model, 1. Decision Rule, 2. Naive Bayes, 3. Decision Tree, and uses concepts of Rough Set for feature selection.\n",
        "\n",
        "\n",
        "\n",
        "### Imports\n",
        "`import pandas as pd` , Pandas is a data python library for manipulation and analysis, pandas is used as the primary dataframe management tool in this project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMqCOP7W5s9_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNjTrd6s5s-B"
      },
      "source": [
        "# Rough Set Theory\n",
        "\n",
        "* Primarily used for feature selection\n",
        "\n",
        "* **Class roughSet** contains member variables **\"dataset\", \"targetsets\" and \"targetset\"**\n",
        "\n",
        "* functions:\n",
        "* * `ind(dataset,targetset,targetsets)` : used to find **Indiscernibility** on a given Information System and Target Set\n",
        "* * `lowerbound(target,datasetind)` : used to find lower bound using `ind()`, takes 1D array of object as target\n",
        "* * `upperbound(target)` : used to find upper bound using `ind()`, takes 1D array of object as target\n",
        "* * `boundary()` : finds boundary region, i.e. the difference between upper and lower bound\n",
        "* * `posetiveRegion(targets,datasetind)` : used to find Posetive Region using union of `lowerbound()`, takes 2D array of object as targets\n",
        "* * `negetiveRegion(targets)` : used to find Negetive Region by substracting union of `upperbound()` from dataset, takes 2D array of object as targets\n",
        "* * `boundaryRegion(targets)` : finds boundary region, i.e objects in upper union but not in lower union\n",
        "* * `iscrisp()` : checks if set is crisp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmEqF4iA5s-B"
      },
      "outputs": [],
      "source": [
        "\n",
        "class roughSet:\n",
        "    columns1=[\"A1\",\"A2\",\"D\"]\n",
        "    dataset1={\"dataset\":[[1,2,0],[1,2,0],[2,0,0],[0,0,1],[2,1,0],[0,0,1],[2,0,0],[0,1,2],[2,1,0],[2,0,0]],\n",
        "    \"targetset\":[1,2,3],\n",
        "    \"targetsets\":[[1,2,3,10],[4,5,9],[6,7,8]]}\n",
        "\n",
        "    dataset=[]\n",
        "    targetset=[]\n",
        "    targetsets=[]\n",
        "    # dataframe=pd.DataFrame(dataset1[\"dataset\"],columns=columns1)\n",
        "\n",
        "    def __init__(self,dataset=dataset1[\"dataset\"],targetset=dataset1[\"targetset\"],targetsets=dataset1[\"targetsets\"]):\n",
        "        self.dataset=dataset\n",
        "        self.targetsets=targetsets\n",
        "        self.targetset=targetset\n",
        "\n",
        "\n",
        "    def setdataset(self,dataframe):\n",
        "        global dataset\n",
        "        dataset=list(zip(*map(dataframe.get,dataframe)))\n",
        "\n",
        "    def ind(self,dataset=None,p=None):\n",
        "        if dataset is None:\n",
        "            dataset=self.dataset\n",
        "        if p is None:\n",
        "            p=[x for x in range(len(self.dataset[0]))]\n",
        "        dic=dict()\n",
        "        seen=[]\n",
        "        # p=[0,2]\n",
        "        # print(p)\n",
        "        for i in range(len(dataset)):\n",
        "            setx=[dataset[i][x] for x in range(len(dataset[i])) if x in p]\n",
        "            # print(seen)\n",
        "            if setx in seen:\n",
        "                dic[seen.index(setx)].append(i+1)\n",
        "            else:\n",
        "                seen.append(setx)\n",
        "                dic[seen.index(setx)]=[i+1]\n",
        "\n",
        "            # print(\"dict===\",dic)\n",
        "        return list(dic.values())\n",
        "\n",
        "    def allin(self,x,target):\n",
        "        for i in x:\n",
        "            if i not in target:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def lowerbound(self,target=None,datasetind=None):\n",
        "        if target==None:\n",
        "            target=self.targetset\n",
        "        result=[]\n",
        "        if datasetind==None:\n",
        "            datasetind=self.ind()\n",
        "        for i in datasetind:\n",
        "            if self.allin(i,target):\n",
        "                [result.append(x) for x in i]\n",
        "        return set(result)\n",
        "\n",
        "\n",
        "    def anyin(self,x,target):\n",
        "        for i in x:\n",
        "            if i in target:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def upperbound(self,target=None):\n",
        "        if target==None:\n",
        "            target=self.targetset\n",
        "        result=[]\n",
        "        for i in self.ind():\n",
        "            if self.anyin(i,target):\n",
        "                [result.append(x) for x in i]\n",
        "        return set(result)\n",
        "\n",
        "    def accuracy(self):\n",
        "        return len(self.lowerbound())*100/len(self.upperbound())\n",
        "\n",
        "    def boundary(self):\n",
        "        lb=self.lowerbound()\n",
        "        result=[]\n",
        "        for i in (self.upperbound()):\n",
        "            if i not in lb:\n",
        "                result.append(i)\n",
        "        return set(result)\n",
        "\n",
        "    def lowerunion(self,targets=None,datasetind=None):\n",
        "        if targets==None:\n",
        "            targets=self.targetsets\n",
        "        result=[]\n",
        "\n",
        "        for i in targets:\n",
        "            [result.append(x) for x in self.lowerbound(i,datasetind=datasetind)]\n",
        "        return set(result)\n",
        "\n",
        "    def posetiveRegion(self,targets=None,datasetind=None):\n",
        "        if targets==None:\n",
        "            targets=self.targetsets\n",
        "        return self.lowerunion(targets,datasetind=datasetind)\n",
        "\n",
        "    def upperunion(self,targets=None):\n",
        "        if targets==None:\n",
        "            targets=self.targetsets\n",
        "        result=[]\n",
        "        for i in targets:\n",
        "            [result.append(x) for x in self.upperbound(i)]\n",
        "        return set(result)\n",
        "\n",
        "    def negetiveRegion(self,targets=None):\n",
        "        if targets==None:\n",
        "            targets=self.targetsets\n",
        "        antiresult=self.upperunion(targets)\n",
        "        result=[x+1 for x in range(len(dataset)) if (x+1) not in antiresult]\n",
        "        return set(result)\n",
        "\n",
        "    def boundaryRegion(self,targets=None):\n",
        "        if targets==None:\n",
        "            targets=self.targetsets\n",
        "        lu=self.lowerunion(targets)\n",
        "        uu=self.upperunion(targets)\n",
        "        result=[x for x in uu if x not in lu]\n",
        "        return set(result)\n",
        "\n",
        "    def iscrisp(self):\n",
        "        if len(self.lowerunion())/len(self.upperunion())==1:\n",
        "            return True\n",
        "        return False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru6bc8wD5s-D"
      },
      "source": [
        "# Reduct and Core\n",
        "\n",
        "* **class reductandcore** has member variables **\"dataframe\"** and **\"y\"**\n",
        "\n",
        "* funtion:\n",
        "* * `core()` : returnes the core of a given dataset using **Discernibility matrix**\n",
        "* * `reduct()` : returnes the reduct of a given dataset using **Modified Quick Reduct Algorithm** *Frequency of non-core attributes in discernibility matrix*\n",
        "* * `hReduced()` : returns a Horizontaly reduced dataset using `reduct()`\n",
        "* * `vReduced()` : returns a Horizontaly and Vertically reduced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJVnS4ZV5s-E"
      },
      "outputs": [],
      "source": [
        "class reductandcore:\n",
        "    def __init__(self, dataframe=None, y=None):\n",
        "        if dataframe is None:\n",
        "            columns = [\"A1\", \"A2\", \"A3\", \"A4\", \"D\"]\n",
        "            dataset = [[\"M\", \"L\", 3, \"M\", 1],\n",
        "                       [\"M\", \"L\", 1, \"H\", 1],\n",
        "                       [\"L\", \"L\", 1, \"M\", 1],\n",
        "                       [\"L\", \"L\", 1, \"M\", 2],\n",
        "                       [\"L\", \"R\", 3, \"M\", 2],\n",
        "                       [\"M\", \"R\", 2, \"M\", 2],\n",
        "                       [\"L\", \"R\", 3, \"L\", 3],\n",
        "                       [\"H\", \"R\", 3, \"L\", 3],\n",
        "                       [\"H\", \"N\", 3, \"L\", 3]]\n",
        "            self.dataframe = pd.DataFrame(dataset, columns=columns)\n",
        "        else:\n",
        "            self.dataframe = dataframe\n",
        "        if y is None:\n",
        "            self.y = \"D\"\n",
        "        else:\n",
        "            self.y = y\n",
        "        # print(self.dataframe)\n",
        "\n",
        "    def core(self):\n",
        "        corematrix = []\n",
        "        datalist = []\n",
        "        deletable = list()\n",
        "        dftemp = self.dataframe.loc[:, self.dataframe.columns != self.y]\n",
        "        dicforcore = {x: 0 for x in dftemp.columns}\n",
        "        dicforcoremain = {x: [] for x in range(len(dftemp.columns)+1)}\n",
        "\n",
        "        # print(len(self.dataframe), self.dataframe[self.y][0])\n",
        "        for i in range(len(self.dataframe)):\n",
        "            ithcorematrix = []\n",
        "            for j in range(i):\n",
        "                if self.dataframe[self.y][i] == self.dataframe[self.y][j]:\n",
        "                    ithcorematrix.append([])\n",
        "                else:\n",
        "                    mismatchlist = []\n",
        "                    for k in dftemp.columns:\n",
        "                        if dftemp[k][i] != dftemp[k][j]:\n",
        "                            # print(dftemp[k][i], dftemp[k][j], end=\" , \")\n",
        "                            mismatchlist.append(k)\n",
        "                            dicforcore[k] += 1\n",
        "                    # print(i, j, mismatchlist)\n",
        "                    dicforcoremain[len(mismatchlist)].append(mismatchlist)\n",
        "                    ithcorematrix.append(mismatchlist)\n",
        "            # print(\"ithcore\", ithcorematrix)\n",
        "\n",
        "            corematrix.append(ithcorematrix)\n",
        "        # for i in deletable:\n",
        "\n",
        "        # print(\"dictfor core main==\", dicforcoremain)\n",
        "        # print(\"friquency ===\", dicforcore)\n",
        "\n",
        "        # print(\"---------------------------Discernibility Matrix------------------------\")\n",
        "        # for i in corematrix:\n",
        "            # print(i)\n",
        "        for i in range(len(dftemp.columns)):\n",
        "            if dicforcoremain[i+1] != []:\n",
        "                corelist = dicforcoremain[i+1]\n",
        "                break\n",
        "        cores = list()\n",
        "        for i in corelist:\n",
        "            for j in i:\n",
        "                cores.append(j)\n",
        "        cores = set(cores)\n",
        "        sortedreducts = [x[0] for x in sorted(\n",
        "            dicforcore.items(), key=lambda x: x[1], reverse=True) if x[0] not in cores]\n",
        "        return {\"core\": cores, \"atts\": sortedreducts}\n",
        "\n",
        "    def reduct(self):\n",
        "        coresandatts = self.core()\n",
        "        cores = coresandatts[\"core\"]\n",
        "        atts = coresandatts[\"atts\"]\n",
        "        # print(cores,atts)\n",
        "        t = cores\n",
        "        dftemp = self.dataframe.loc[:, self.dataframe.columns != self.y]\n",
        "        ddtemp = self.dataframe[[self.y]]\n",
        "        rsdd = roughSet(dataset=ddtemp.values.tolist())\n",
        "        indD = rsdd.ind()\n",
        "        # print(\"ind D=== \",indD)\n",
        "        rsdf = roughSet(dataset=dftemp.values.tolist())\n",
        "        indcore = rsdf.ind(\n",
        "            p=[x for x in range(len(dftemp.columns)) if dftemp.columns[x] in cores])\n",
        "        # print(\"ind core==\",indcore)\n",
        "        T = list(cores)\n",
        "        # print(\"cores\",cores,T)\n",
        "\n",
        "        lowerunionwithcore = rsdf.posetiveRegion(\n",
        "            targets=indD, datasetind=indcore)\n",
        "        # print(\"Lower union== \",lowerunionwithcore)\n",
        "        gama = len(lowerunionwithcore)/len(dftemp.index)\n",
        "        # print(\"gamma core====\",gama)\n",
        "        for i in atts:\n",
        "            tempT = T.copy()\n",
        "            tempT.append(i)\n",
        "            # print(\"tempt=\",tempT)\n",
        "            indiT = rsdf.ind(\n",
        "                p=[x for x in range(len(dftemp.columns)) if dftemp.columns[x] in tempT])\n",
        "            # print(\"ind ====== T \",T,\" is \",indiT)\n",
        "            lowerunion = rsdf.posetiveRegion(targets=indD, datasetind=indiT)\n",
        "            # print(\"Lower union== \",lowerunion)\n",
        "            gamatemp = len(lowerunion)/len(dftemp.index)\n",
        "            # print(\"new gamma===\",gamatemp)\n",
        "            if gamatemp > gama:\n",
        "                gama = gamatemp\n",
        "                T = tempT.copy()\n",
        "            # print(\"new t=\",T)\n",
        "        return T\n",
        "\n",
        "    def hReduced(self):\n",
        "        red = self.reduct()\n",
        "        red.append(self.y)\n",
        "        dfred = self.dataframe[red]\n",
        "        return dfred\n",
        "\n",
        "    def vReduced(self):\n",
        "        hred = self.hReduced()\n",
        "        vred = hred.drop_duplicates()\n",
        "        return vred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNfoQgwt5s-G"
      },
      "source": [
        "# Decision Rule\n",
        "* A decision rule is a set of conditions that classify records.\n",
        "* It is a **custom build classification model** build using concepts of Rough Set Theory.\n",
        "\n",
        "* **class decisionRuleGen** has functions:\n",
        "* * `rule_gen(train,y)` : generates a ruleset on a given training pandas dataframe and class column name \"y\", for each class a list of rules is produced, each rule consist of list of dicts.\n",
        "* * `predict(testset)` : generates a 2D array of predicted class of classless test dataframe, by matching the the object with the rules using `matches()`, values in dicts of each rule are compared in OR condition and all dicts in a rule is compared in AND, if any of the rule match the corrosponding class is returned.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTkujNvT5s-G"
      },
      "outputs": [],
      "source": [
        "class decisionRuleGen:\n",
        "    rules=dict()\n",
        "    def finddiff(self,j,k):\n",
        "        res=dict()\n",
        "        for i in range(len(j)):\n",
        "            if(j.iloc[i]!=k.iloc[i]):\n",
        "                res[i]=j.iloc[i]\n",
        "\n",
        "        return res\n",
        "\n",
        "\n",
        "    def printmat(self,mat):\n",
        "        for i in mat:\n",
        "            print(i)\n",
        "            print(\"\\n\")\n",
        "\n",
        "    def rule_gen(self,train,y):\n",
        "        global rules\n",
        "        classlessdataframe=train.drop([y],axis=1)\n",
        "        decisionmatrix=dict()\n",
        "        for i in list(train[y].unique()):\n",
        "            dmy=classlessdataframe[train[y]==i]\n",
        "            dmx=classlessdataframe[train[y]!=i]\n",
        "            unique=list()\n",
        "            for index,rowsy in dmy.iterrows():\n",
        "                unique1=list()\n",
        "                seen=[]\n",
        "                for index,rowsx in dmx.iterrows():\n",
        "                    unique11=self.finddiff(rowsy,rowsx)\n",
        "                    unique1.append(unique11.copy())\n",
        "                    # print(\"1st : \",unique11)\n",
        "                    # if [x for x in unique11 if x in seen]==[]:\n",
        "                    #     unique1.append(unique11.copy())\n",
        "                    #     for x in unique11:\n",
        "                    #         seen.append(x)\n",
        "                    #     print(seen)\n",
        "                # print(\"2nd : \",unique1)\n",
        "                unique.append(unique1.copy())\n",
        "            # print(\"finally : \",unique)\n",
        "            decisionmatrix[i]=unique.copy()\n",
        "        # print(decisionmatrix)\n",
        "        rules=decisionmatrix\n",
        "        return decisionmatrix\n",
        "\n",
        "\n",
        "    def matches(self,obj,ruleset):\n",
        "            # print(obj)\n",
        "            for i in ruleset:               #OR\n",
        "                # print(\"i \",i)               #OR\n",
        "                for j in i:                 #AND\n",
        "                    # print(\"j \",j)           #AND\n",
        "                    flag=0                  #AND\n",
        "                    match=1                 #AND\n",
        "                    for k in j:\n",
        "                        # print(f\"testing for {k} {j[k]},{obj[k]}\")            #OR\n",
        "                        if obj.iloc[k]==j[k]:    #OR\n",
        "                            # print(f\"---match for {k} ({i.index(j)}/{len(i)})\")\n",
        "                            flag=1          #OR\n",
        "                            break           #OR\n",
        "                    if flag==0:             #AND\n",
        "                        # print(f\"------didnt match for {j}\")\n",
        "                        match=0             #AND\n",
        "                        break               #AND\n",
        "            if match==0:                #OR\n",
        "                return False\n",
        "            # print(f\"--------------finally {obj} match for {i}\")\n",
        "            return True\n",
        "\n",
        "    def predict(self,testset):\n",
        "            global rules\n",
        "            res=list()\n",
        "            # print(len(testset))\n",
        "            for index,i in testset.iterrows():\n",
        "                rest=list()\n",
        "                for j in rules:\n",
        "                    # print(rules[j])\n",
        "                    if(self.matches(i,rules[j])):\n",
        "                        # print(j)\n",
        "                        rest.append(j)\n",
        "                        # break\n",
        "                res.append(rest)\n",
        "                # print(index, \" done \", res)\n",
        "            return res\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU0JbjXq5s-H"
      },
      "source": [
        "# Naive Bayes\n",
        "* Describes the probability of an event, based on prior knowledge of conditions that might be related to the event.\n",
        "* It is a **custom build classifier model** built using Bayes Theorum of probablity.\n",
        "\n",
        "* **class NaieveBayes** has functions:\n",
        "* * `train(d,y)` : sets data for running probablity of object based on.\n",
        "* * `predict(y)` : predicts class of each object in the test dataframe and returnes a 2D list of predictions, predictions are made based on Bayes Theorum of finding probablity of and event occouring, provided another event has already occoured, for every object in classless test set, every attribute is considered and probablity of that attribute happening to be in each class is computed. all the attributs probablity is multiplied and finally divided by the probablity of a class happening. Finally whichever class has the highest probablity given the object's attributes is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1t5FSwr5s-I"
      },
      "outputs": [],
      "source": [
        "class NaieveBayes:\n",
        "    data=[]\n",
        "    y=\"\"\n",
        "    def train(self,d,y):\n",
        "        self.data=d\n",
        "        self.y=y\n",
        "    def prob(self,data,y):\n",
        "        return len(data[data==y])/len(data)\n",
        "    def probnb(self,x,y,classlen):\n",
        "        if(x!=0):\n",
        "            return(x/y)\n",
        "        else:\n",
        "            return(1/(y+classlen))\n",
        "    def predict(self,y):\n",
        "        pci=dict()\n",
        "        count=dict()\n",
        "        totcount=len(self.data)\n",
        "        for yunique in self.data[self.y].unique():\n",
        "            pci[yunique]=self.prob(self.data[self.y],yunique)\n",
        "            count[yunique]=len(self.data[self.data[self.y]==yunique])\n",
        "        # print(pci)\n",
        "        # print(count)\n",
        "        # print(totcount)\n",
        "        # pxci=dict()\n",
        "        cols=list(y.columns)\n",
        "        res=list()\n",
        "        for index,row in y.iterrows():\n",
        "            pximul={x:1 for x in self.data[self.y].unique()}\n",
        "            for j in cols:\n",
        "                for yunique in count:\n",
        "                    # print(yunique,row[j])\n",
        "                    # self.probnb(j,(self.data[self.data[j]==row[j]),count[yunique])\n",
        "                    dftemp=self.data[self.data[j]==row[j]]\n",
        "                    # print(row[j],yunique)\n",
        "                    temppxi=self.probnb(len(dftemp[dftemp[self.y]==yunique]),count[yunique],len(count))\n",
        "                    # print(temppxi)\n",
        "                    pximul[yunique]*=temppxi\n",
        "                    # print(yunique,pximul[yunique])\n",
        "            # print(pximul)\n",
        "            resdic=dict()\n",
        "            for i in pximul:\n",
        "                resdic[i]=pximul[i]*pci[i]\n",
        "            # print(\"Probablity for object no.:\",index,\" belonging to:\",resdic,end=\" \")\n",
        "\n",
        "            inverse = [(value, key) for key, value in resdic.items()]\n",
        "            # print(max(inverse)[1])\n",
        "            res.append([max(inverse)[1]])\n",
        "        return res\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfxRaN9k5s-I"
      },
      "source": [
        "# Decision Tree\n",
        "* The decision tree classifier creates the classification model by building a decision tree. Each node in the tree specifies a test on an attribute, each branch descending from that node corresponds to one of the possible values for that attribute.\n",
        "\n",
        "* It is **classification model** that uses Gain Ratio for Attribute Selection\n",
        "\n",
        "### Imports\n",
        "* * `from sklearn.tree import DecisionTreeClassifier` : DecisionTreeClassifier is a classification model that is used to build a decision tree, based on Information System which is then used to determine the class of unclassified data.\n",
        "* * `from sklearn.preprocessing import OneHotEncoder` : One hot encoding is a technique that we use to represent categorical variables as numerical values, as the *DecisionTreeClassifier* model works efficiently on numerical values. This method is used to eleminate string categorical values from the Information System.\n",
        "\n",
        "* **class DecisionTree** has functions:\n",
        "* * `train_and_predict(train_data, class_column, test_data)` : takes a training pandas dataframe, class column name and unclassified test pandas dataframe. The Model is trained using the training data after encoding the dataframe using One Hot Encoding technique, the test dataframe is also encoded with the same categorical values and is used for prediction. Returns a list of predicted values of the unclassified testset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slnUxf9m5s-J"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "class DecisionTree:\n",
        "    def dfconcat(self,lis,axis):\n",
        "        df1=lis[0]\n",
        "        df2=lis[1]\n",
        "        if not df1.empty and not df2.empty:\n",
        "            result_df = pd.concat([df1, df2], axis=0)\n",
        "        elif not df1.empty:\n",
        "            result_df = df1.copy()\n",
        "        elif not df2.empty:\n",
        "            result_df = df2.copy()\n",
        "        else:\n",
        "            result_df = pd.DataFrame()\n",
        "        return result_df\n",
        "\n",
        "    def train_and_predict(self,train_data, class_column, test_data):\n",
        "        # Extract features and target variable from train data\n",
        "        X_train = train_data.drop(columns=[class_column])\n",
        "        y_train = train_data[class_column]\n",
        "\n",
        "        # One-hot encode categorical columns in train data\n",
        "        categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "        encoder = OneHotEncoder(drop='first', sparse=False,handle_unknown='ignore')\n",
        "        X_train.reset_index(drop=True,inplace=True)\n",
        "        X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_cols]))\n",
        "\n",
        "        X_train = self.dfconcat([X_train.drop(columns=categorical_cols), X_train_encoded], axis=1)\n",
        "\n",
        "        # Initialize DecisionTreeClassifier\n",
        "        clf = DecisionTreeClassifier()\n",
        "\n",
        "        # Train the classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "        # One-hot encode categorical columns in test data\n",
        "        test_data.reset_index(drop=True,inplace=True)\n",
        "        X_test_encoded = pd.DataFrame(encoder.transform(test_data[categorical_cols]))\n",
        "        X_test = self.dfconcat([test_data.drop(columns=categorical_cols), X_test_encoded], axis=1)\n",
        "\n",
        "        # Make predictions on test data\n",
        "        predictions = clf.predict(X_test)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "# Example usage:\n",
        "# dataframe = pd.read_csv(\"computerData.csv\")\n",
        "# print(dataframe)\n",
        "# for i in dataframe:\n",
        "#     if dataframe.dtypes[i]==\"int64\":\n",
        "#         dataframe[i]=dataframe[i].astype(str)\n",
        "# train_df = dataframe.iloc[:10,:]\n",
        "# test_df = dataframe.iloc[10:,:].drop(columns=[\"class\"])\n",
        "# dt=DecisionTree()\n",
        "# print(len(test_df))\n",
        "# predictions = dt.train_and_predict(train_df, 'class', test_df)\n",
        "# print(predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6G7W7nT5s-J"
      },
      "source": [
        "# Printing Performance\n",
        "**`printingAPRF(results,actual)`** : funtion used to calculate Accuracy, Precision, Recall and F1Score of model from predictions and actual results. This funtion returnes a dictionary containing 4 keys: Accuracy, Precision, Recall and F1Score and there corrosponding values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC3ZWDC25s-K"
      },
      "outputs": [],
      "source": [
        "def printingAPRF(results,actual):\n",
        "    truepos=0\n",
        "    trueneg=0\n",
        "    falsepos=0\n",
        "    falseneg=0\n",
        "    actual=actual.tolist()\n",
        "    # print(len(actual),len(results),results)\n",
        "    for i in range(len(actual)):\n",
        "        # print(i,actual[i],results[i],actual[i] in results[i])\n",
        "        if actual[i] in results[i]:\n",
        "            if 'n' in actual[i] or 'N' in actual[i]:\n",
        "                trueneg+=1\n",
        "            else:\n",
        "                truepos+=1\n",
        "        else:\n",
        "            if 'n' in actual[i] or 'N' in actual[i]:\n",
        "                falseneg+=1\n",
        "            else:\n",
        "                falsepos+=1\n",
        "    temp=(trueneg+truepos+falseneg+falsepos)\n",
        "    accuracy=((truepos+trueneg)/temp) if temp!=0 else 1\n",
        "    # print(\"Accuracy : \",accuracy)\n",
        "    temp=(truepos+falsepos)\n",
        "    precision=(truepos/temp) if temp!=0 else 1\n",
        "    # print(\"Precision : \",precision)\n",
        "    temp=(truepos+falseneg)\n",
        "    recall=(truepos/temp) if temp!=0 else 1\n",
        "    # print(\"Recall : \",recall)\n",
        "    temp=(precision+recall)\n",
        "    f1score=((2*precision*recall)/temp) if temp!=0 else 1\n",
        "    # print(\"F1 Score : \",f1score)\n",
        "    return {\"Accuracy\":accuracy,\"Precision\":precision,\"Recall\":recall,\"F1 Score\":f1score}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll4XnN765s-K"
      },
      "source": [
        "# Training and Testing Funtions\n",
        "* These funtions take classifide train and test data, and returnes a dict containing keys actual test,actual train, test result, and train result and there corrosponding values,\n",
        "* * \"actual test\" contains the actual classes of the Test data\n",
        "* * \"actual train\" contains the actual classes of the Train data\n",
        "* * \"test result\" contains the predicted classes of the Test data\n",
        "* * \"train result\" contains the predicted classes of the Train data\n",
        "\n",
        "* **`decisionModelTester(test,train)`** : generate decision rules based on training data using the Decision Rule model, and predicts the class of unclassified test data.\n",
        "* **`naiveBayesModelTester(test,train)`** : predicts the class of unclassified test data using classified test data as experience for implimenting Bayes Probablity Theorum.\n",
        "* **`decisionModelTester(test,train)`** : generate decision tree based on training data using the Decision Tree model, and predicts the class of unclassified test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbe0yMj05s-K"
      },
      "outputs": [],
      "source": [
        "def decisionModelTester(test,train):\n",
        "    global y\n",
        "    dr=decisionRuleGen()\n",
        "    rules=dr.rule_gen(train,y)\n",
        "    classlesstrain=train.drop([y],axis=1)\n",
        "    classlesstest=test.drop([y],axis=1)\n",
        "    testresults=dr.predict(classlesstest)\n",
        "    trainresults=dr.predict(classlesstrain)\n",
        "    # print(\"this is ttest[y]\",test[y])\n",
        "    actualtest=test[y]\n",
        "    actualtrain=train[y]\n",
        "    return {\"actual test\":actualtest,\"actual train\":actualtrain,\"test result\":testresults,\"train result\":trainresults}\n",
        "\n",
        "def naiveBayesModelTester(test,train):\n",
        "    global y\n",
        "    dr=NaieveBayes()\n",
        "    dr.train(train,y)\n",
        "    classlesstrain=train.drop([y],axis=1)\n",
        "    classlesstest=test.drop([y],axis=1)\n",
        "    testresults=dr.predict(classlesstest)\n",
        "    trainresults=dr.predict(classlesstrain)\n",
        "    actualtest=test[y]\n",
        "    actualtrain=train[y]\n",
        "    return {\"actual test\":actualtest,\"actual train\":actualtrain,\"test result\":testresults,\"train result\":trainresults}\n",
        "\n",
        "def treeModelTester(test,train):\n",
        "    global y\n",
        "    dr=DecisionTree()\n",
        "    classlesstrain=train.drop([y],axis=1)\n",
        "    classlesstest=test.drop([y],axis=1)\n",
        "    testresults=dr.train_and_predict(train, y, classlesstest)\n",
        "    testresults=[[x] for x in testresults]\n",
        "    trainresults=dr.train_and_predict(train, y, classlesstrain)\n",
        "    trainresults=[[x] for x in trainresults]\n",
        "    actualtest=test[y]\n",
        "    actualtrain=train[y]\n",
        "    return {\"actual test\":actualtest,\"actual train\":actualtrain,\"test result\":testresults,\"train result\":trainresults}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlbZLS3k5s-L"
      },
      "source": [
        "# Data Set\n",
        "### We use *`diabetes_dataset.csv`* for testing and training our models and compairing there classification ability\n",
        "* The index column is dropped and the final shape is printed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEoMNOb95s-L",
        "outputId": "6abfa560-cca0-4d7d-a0bb-0e5b4035651f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
            "0   40   Male       No        Yes                 No      Yes         No   \n",
            "1   60   Male       No         No                 No      Yes         No   \n",
            "2   50   Male      Yes         No                 No      Yes        Yes   \n",
            "3   50   Male       No         No                Yes      Yes        Yes   \n",
            "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
            "\n",
            "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
            "0             No              No     Yes           No             Yes   \n",
            "1             No             Yes      No           No              No   \n",
            "2             No              No     Yes           No             Yes   \n",
            "3            Yes              No     Yes           No             Yes   \n",
            "4             No             Yes     Yes          Yes             Yes   \n",
            "\n",
            "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
            "0              No              Yes      Yes     Yes  Positive  \n",
            "1             Yes               No      Yes      No  Positive  \n",
            "2              No              Yes      Yes      No  Positive  \n",
            "3              No               No       No      No  Positive  \n",
            "4             Yes              Yes      Yes     Yes  Positive   (520, 17)\n"
          ]
        }
      ],
      "source": [
        "originaldataframe=pd.read_csv(\"diabetes_dataset.csv\")\n",
        "originaldataframe.reset_index(drop=True,inplace=True)\n",
        "print(originaldataframe.head(),originaldataframe.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC8AHQqu5s-M"
      },
      "source": [
        "# Reduced Data Set\n",
        "* Decision class name - \"class\" is stored in variable `y`,\n",
        "* The dataframe is reduced using concepts of Rough Set Theory. `redandcode` is an object of **class reductandcore** which is fitted with original dataframe and class name, `.vReduced()` funtion returnes the reduced dataframe.\n",
        "* Shape of reduced dataframe is printed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cy_eERQq5s-M",
        "outputId": "e5299f4a-485b-465b-b43d-8f67a1e571a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  sudden weight loss weakness Gender Obesity Polydipsia  Age Polyuria  \\\n",
            "0                 No      Yes   Male     Yes        Yes   40       No   \n",
            "1                 No      Yes   Male      No         No   60       No   \n",
            "2                 No      Yes   Male      No         No   50      Yes   \n",
            "3                Yes      Yes   Male      No         No   50       No   \n",
            "4                Yes      Yes   Male     Yes        Yes   60      Yes   \n",
            "\n",
            "  partial paresis Polyphagia visual blurring Alopecia Itching     class  \n",
            "0              No         No              No      Yes     Yes  Positive  \n",
            "1             Yes         No             Yes      Yes      No  Positive  \n",
            "2              No        Yes              No      Yes     Yes  Positive  \n",
            "3              No        Yes              No       No     Yes  Positive  \n",
            "4             Yes        Yes             Yes      Yes     Yes  Positive   \n",
            "shape of reduced data= (219, 13)\n"
          ]
        }
      ],
      "source": [
        "y=\"class\"\n",
        "redandcore=reductandcore(dataframe=originaldataframe,y=y)\n",
        "dataframe=redandcore.vReduced()\n",
        "print(dataframe.head(),\"\\nshape of reduced data=\",dataframe.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrBAcOQr5s-N"
      },
      "source": [
        "# K Fold cross validation\n",
        "\n",
        "* Variable `k` is used to store the number of foldes used to cross verify the training and testing data\n",
        "* Dataframe is split into corrosponing ratio (for k=5, test:train = 20:80)\n",
        "* The test and training datas are passed on to training and testing funtions\n",
        "* The predicted and actual class values returned from the testiing funtion is passed to the `printingAPRF()` funtion which returnes the performance scores of the models.\n",
        "* The Accuracy, Precision, Recall and F1Score of the model are printed on both the test and training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSy0QT2N5s-N",
        "outputId": "f0476cba-e9aa-4d5f-c5b2-68f8579a9a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "Fold -- 1\n",
            "test shape (43, 13), train shape (176, 13) \n",
            "\n",
            "DECISION RULE\n",
            "Test Score:\n",
            "{'Accuracy': 0.8837209302325582, 'Precision': 0.8837209302325582, 'Recall': 1.0, 'F1 Score': 0.9382716049382717}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.8522727272727273, 'Precision': 0.9495798319327731, 'Recall': 0.849624060150376, 'F1 Score': 0.8968253968253969}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "NAIEVE BAYES\n",
            "Test Score:\n",
            "{'Accuracy': 0.813953488372093, 'Precision': 0.813953488372093, 'Recall': 1.0, 'F1 Score': 0.8974358974358974}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.8522727272727273, 'Precision': 0.8487394957983193, 'Recall': 0.926605504587156, 'F1 Score': 0.8859649122807017}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "DECISION TREE\n",
            "Test Score:\n",
            "{'Accuracy': 0.8837209302325582, 'Precision': 0.8837209302325582, 'Recall': 1.0, 'F1 Score': 0.9382716049382717}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.9943181818181818, 'Precision': 0.9915966386554622, 'Recall': 1.0, 'F1 Score': 0.9957805907172996}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "\n",
            "-----------------------------------------\n",
            "Fold -- 2\n",
            "test shape (43, 13), train shape (176, 13) \n",
            "\n",
            "DECISION RULE\n",
            "Test Score:\n",
            "{'Accuracy': 0.9534883720930233, 'Precision': 0.9534883720930233, 'Recall': 1.0, 'F1 Score': 0.9761904761904763}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.8352272727272727, 'Precision': 0.9243697478991597, 'Recall': 0.8461538461538461, 'F1 Score': 0.8835341365461847}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "NAIEVE BAYES\n",
            "Test Score:\n",
            "{'Accuracy': 0.7209302325581395, 'Precision': 0.7209302325581395, 'Recall': 1.0, 'F1 Score': 0.8378378378378378}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.8693181818181818, 'Precision': 0.8823529411764706, 'Recall': 0.9210526315789473, 'F1 Score': 0.9012875536480687}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "DECISION TREE\n",
            "Test Score:\n",
            "{'Accuracy': 0.7906976744186046, 'Precision': 0.7906976744186046, 'Recall': 1.0, 'F1 Score': 0.8831168831168831}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1 Score': 1.0}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "\n",
            "-----------------------------------------\n",
            "Fold -- 3\n",
            "test shape (43, 13), train shape (176, 13) \n",
            "\n",
            "DECISION RULE\n",
            "Test Score:\n",
            "{'Accuracy': 0.9534883720930233, 'Precision': 0.9534883720930233, 'Recall': 1.0, 'F1 Score': 0.9761904761904763}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.8125, 'Precision': 0.9243697478991597, 'Recall': 0.8208955223880597, 'F1 Score': 0.8695652173913043}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "NAIEVE BAYES\n",
            "Test Score:\n",
            "{'Accuracy': 0.9069767441860465, 'Precision': 0.9069767441860465, 'Recall': 1.0, 'F1 Score': 0.951219512195122}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.8522727272727273, 'Precision': 0.8487394957983193, 'Recall': 0.926605504587156, 'F1 Score': 0.8859649122807017}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "DECISION TREE\n",
            "Test Score:\n",
            "{'Accuracy': 0.8604651162790697, 'Precision': 0.8604651162790697, 'Recall': 1.0, 'F1 Score': 0.9249999999999999}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.9943181818181818, 'Precision': 0.9915966386554622, 'Recall': 1.0, 'F1 Score': 0.9957805907172996}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "\n",
            "-----------------------------------------\n",
            "Fold -- 4\n",
            "test shape (43, 13), train shape (176, 13) \n",
            "\n",
            "DECISION RULE\n",
            "Test Score:\n",
            "{'Accuracy': 0.6976744186046512, 'Precision': 0.9642857142857143, 'Recall': 0.6923076923076923, 'F1 Score': 0.8059701492537313}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.8863636363636364, 'Precision': 0.9402985074626866, 'Recall': 0.9130434782608695, 'F1 Score': 0.9264705882352942}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "NAIEVE BAYES\n",
            "Test Score:\n",
            "{'Accuracy': 0.8837209302325582, 'Precision': 0.8928571428571429, 'Recall': 0.9259259259259259, 'F1 Score': 0.9090909090909091}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.8693181818181818, 'Precision': 0.8805970149253731, 'Recall': 0.944, 'F1 Score': 0.9111969111969112}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "DECISION TREE\n",
            "Test Score:\n",
            "{'Accuracy': 0.6511627906976745, 'Precision': 0.7142857142857143, 'Recall': 0.7407407407407407, 'F1 Score': 0.7272727272727273}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.9943181818181818, 'Precision': 0.9925373134328358, 'Recall': 1.0, 'F1 Score': 0.9962546816479401}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "\n",
            "-----------------------------------------\n",
            "Fold -- 5\n",
            "test shape (43, 13), train shape (176, 13) \n",
            "\n",
            "DECISION RULE\n",
            "Test Score:\n",
            "{'Accuracy': 0.6976744186046512, 'Precision': 1.0, 'Recall': 0.13333333333333333, 'F1 Score': 0.23529411764705882}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.9034090909090909, 'Precision': 0.96875, 'Recall': 0.9281437125748503, 'F1 Score': 0.9480122324159022}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "NAIEVE BAYES\n",
            "Test Score:\n",
            "{'Accuracy': 0.4883720930232558, 'Precision': 1.0, 'Recall': 0.08333333333333333, 'F1 Score': 0.15384615384615385}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 0.9204545454545454, 'Precision': 0.9375, 'Recall': 0.974025974025974, 'F1 Score': 0.9554140127388535}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "DECISION TREE\n",
            "Test Score:\n",
            "{'Accuracy': 0.3023255813953488, 'Precision': 1.0, 'Recall': 0.0625, 'F1 Score': 0.11764705882352941}\n",
            "-------------------------\n",
            "Train Score:\n",
            "{'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1 Score': 1.0}\n",
            "------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "k=5\n",
        "no_of_rows=len(dataframe)\n",
        "splitsize=int(no_of_rows/k)\n",
        "\n",
        "score={\"test\":{\"decisionrule\":dict(),\"naievebayes\":dict(),\"decisiontree\":dict()},\"train\":{\"decisionrule\":dict(),\"naievebayes\":dict(),\"decisiontree\":dict()}}\n",
        "for i in dataframe:\n",
        "    if dataframe.dtypes[i]==\"int64\":\n",
        "        dataframe[i]=dataframe[i].astype(str)\n",
        "for i in range(k):\n",
        "    test=dataframe.iloc[i*splitsize:(i+1)*splitsize,:]\n",
        "    train1=dataframe.iloc[0:i*splitsize,:]\n",
        "    train2=dataframe.iloc[(i+1)*splitsize:,:]\n",
        "    train=pd.concat([train1,train2])\n",
        "    print(f\"-----------------------------------------\\nFold -- {i+1}\")\n",
        "    print(f\"test shape {test.shape}, train shape {train.shape} \\n\")\n",
        "\n",
        "    decisionrule=decisionModelTester(test,train)\n",
        "    score[\"test\"][\"decisionrule\"][i]=printingAPRF(decisionrule[\"test result\"],decisionrule[\"actual test\"])\n",
        "    score[\"train\"][\"decisionrule\"][i]=printingAPRF(decisionrule[\"train result\"],decisionrule[\"actual train\"])\n",
        "    print(\"DECISION RULE\")\n",
        "    print(\"Test Score:\")\n",
        "    print(score[\"test\"][\"decisionrule\"][i])\n",
        "    print(\"-------------------------\")\n",
        "    print(\"Train Score:\")\n",
        "    print(score[\"train\"][\"decisionrule\"][i])\n",
        "    print(\"------------------------------------------------------------------\\n\")\n",
        "\n",
        "    naievebayes=naiveBayesModelTester(test,train)\n",
        "    score[\"test\"][\"naievebayes\"][i]=printingAPRF(naievebayes[\"test result\"],naievebayes[\"actual test\"])\n",
        "    score[\"train\"][\"naievebayes\"][i]=printingAPRF(naievebayes[\"train result\"],naievebayes[\"actual train\"])\n",
        "    print(\"NAIEVE BAYES\")\n",
        "    print(\"Test Score:\")\n",
        "    print(score[\"test\"][\"naievebayes\"][i])\n",
        "    print(\"-------------------------\")\n",
        "    print(\"Train Score:\")\n",
        "    print(score[\"train\"][\"naievebayes\"][i])\n",
        "    print(\"------------------------------------------------------------------\\n\")\n",
        "\n",
        "    decisiontree=treeModelTester(test,train)\n",
        "    score[\"test\"][\"decisiontree\"][i]=printingAPRF(decisiontree[\"test result\"],decisiontree[\"actual test\"])\n",
        "    score[\"train\"][\"decisiontree\"][i]=printingAPRF(decisiontree[\"train result\"],decisiontree[\"actual train\"])\n",
        "    print(\"DECISION TREE\")\n",
        "    print(\"Test Score:\")\n",
        "    print(score[\"test\"][\"decisiontree\"][i])\n",
        "    print(\"-------------------------\")\n",
        "    print(\"Train Score:\")\n",
        "    print(score[\"train\"][\"decisiontree\"][i])\n",
        "    print(\"------------------------------------------------------------------\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4np0j_w5s-N"
      },
      "source": [
        "# CONCLUSION\n",
        "## The average performance of each of the model based on seen and unseen data is printed:\n",
        "\n",
        "* It is seen that the Decision Rule model performs best on unseen data, Accuracy, Precision and F1Score wise.\n",
        "* Naive Bayes classifier model perform next best on unseen data, but has the highest Recall.\n",
        "* The Decision Tree classifier model performs the worst among the three on unseen data, Accuracy, Precision, Recall and F1score wise.\n",
        "\n",
        "* On the other hand on seen data, the Decision Tree classifier model performs the best among the three, Accuracy, Precision, Recall and F1score wise.\n",
        "* Naive Bayes classifier model perform next best on seen data, but has the lowest Precision.\n",
        "* The Decision Rule model performs worst on seen data, Accuracy, Recall and F1score wise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeypCuZe5s-O",
        "outputId": "0ca03fc8-4e1b-4f7e-8144-ddce3f66dac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AVERGE PERFORMANCE\n",
            "---------------------------------------------\n",
            "ON UNSEEN DATA:\n",
            "     DECISION RULE\n",
            "          {'Accuracy': 0.8372093023255814, 'Precision': 0.9509966777408639, 'Recall': 0.7651282051282051, 'F1 Score': 0.786383364844003}\n",
            "     NAIEVE BAYES\n",
            "          {'Accuracy': 0.7627906976744185, 'Precision': 0.8669435215946845, 'Recall': 0.8018518518518519, 'F1 Score': 0.749886062081184}\n",
            "     DECISION TREE\n",
            "          {'Accuracy': 0.6976744186046513, 'Precision': 0.8498338870431894, 'Recall': 0.7606481481481481, 'F1 Score': 0.7182616548302823}\n",
            "\n",
            "ON SEEN DATA:\n",
            "     DECISION RULE\n",
            "          {'Accuracy': 0.8579545454545455, 'Precision': 0.9414735670387557, 'Recall': 0.8715721239056003, 'F1 Score': 0.9048815142828165}\n",
            "     NAIEVE BAYES\n",
            "          {'Accuracy': 0.8727272727272727, 'Precision': 0.8795857895396966, 'Recall': 0.9384579229558467, 'F1 Score': 0.9079656604290474}\n",
            "     DECISION TREE\n",
            "          {'Accuracy': 0.996590909090909, 'Precision': 0.995146118148752, 'Recall': 1.0, 'F1 Score': 0.9975631726165078}\n"
          ]
        }
      ],
      "source": [
        "def avgscore(dic):\n",
        "    res={'Accuracy': 0, 'Precision': 0, 'Recall': 0, 'F1 Score': 0}\n",
        "    for i in dic:\n",
        "        for j in dic[i]:\n",
        "            res[j]=res[j]+dic[i][j]\n",
        "    for i in res:\n",
        "        res[i]=res[i]/len(dic)\n",
        "    return res\n",
        "\n",
        "print(\"AVERGE PERFORMANCE\\n---------------------------------------------\")\n",
        "print(\"ON UNSEEN DATA:\")\n",
        "print(\"     DECISION RULE\")\n",
        "print(\"         \",avgscore(score[\"test\"][\"decisionrule\"]))\n",
        "print(\"     NAIEVE BAYES\")\n",
        "print(\"         \",avgscore(score[\"test\"][\"naievebayes\"]))\n",
        "print(\"     DECISION TREE\")\n",
        "print(\"         \",avgscore(score[\"test\"][\"decisiontree\"]))\n",
        "print(\"\\nON SEEN DATA:\")\n",
        "print(\"     DECISION RULE\")\n",
        "print(\"         \",avgscore(score[\"train\"][\"decisionrule\"]))\n",
        "print(\"     NAIEVE BAYES\")\n",
        "print(\"         \",avgscore(score[\"train\"][\"naievebayes\"]))\n",
        "print(\"     DECISION TREE\")\n",
        "print(\"         \",avgscore(score[\"train\"][\"decisiontree\"]))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}